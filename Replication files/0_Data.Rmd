---
title: "Data Importation, Merging, and Collating"
author: "Michelle Schultze"
date: "Sept 21, 2024"
output:
  pdf_document:
    toc: yes
  html_document:
    toc: yes
    toc_float: yes
---
---

```{r packages, message=FALSE, warning=FALSE}
library(tidyverse)
library(dplyr)
library(readr)
library(readxl)

setwd("/Users/michelle/Documents/ukr2024/All Research Documents (Feb-Sept 2024)/backups/mar 5 backup/UKR-airports/data")
```

##ACLED DATA
Original (daily) data files can be downloaded from the ACLED website (not included in project folder). 
The code below was used to aggregate the data into a monthly form.
The endpoint merged data used in the model is stored within master_dataset.csv.

Bring in ACLED index data. (Takes 2 mins)
```{r ACLED-merge, eval=FALSE, include=FALSE}
ACLED <- read_csv("data/ACLED index/ACLED_master.csv")

# merge ACLED sets together (had to be downloaded in segments)
ACLED1 <- read_csv("data/ACLED index/1997-01-01-2001-01-01.csv")
ACLED2 <- read_csv("data/ACLED index/2001-01-01-2011-01-01.csv")
ACLED3 <- read_csv("data/ACLED index/2011-01-01-2017-01-01.csv")
ACLED4 <- read_csv("data/ACLED index/2017-01-01-2018-01-01.csv")
ACLED5 <- read_csv("data/ACLED index/2018-01-01-2019-01-01.csv")
ACLED6 <- read_csv("data/ACLED index/2019-01-01-2021-01-01.csv")
ACLED7 <- read_csv("data/ACLED index/2021-01-01-2023-01-01.csv")
ACLED8 <- read_csv("data/ACLED index/2023-01-01-2024-01-01.csv")
ACLED <- full_join(ACLED1, full_join(ACLED2, full_join(ACLED3, full_join(ACLED4, full_join(ACLED5, full_join(ACLED6, full_join(ACLED7, ACLED8)))))))

#Check to make sure all observations are unique in the merged set
group_by(ACLED, event_id_cnty) %>%
  summarize(n_id = n()) %>%
  arrange(descending = TRUE)
# true — no repeats

write.csv(ACLED, "data/ACLED index/ACLED_master.csv")
```

Aggregate and merge ACLED indicators
```{r ACLED-tidy, eval=FALSE, include=FALSE}
ACLED2 <- ACLED %>%
  mutate(event_date = as.Date(ACLED$event_date, "%d %B %Y"))

ACLED_day <- ACLED2 %>%
  group_by(event_date, country) %>%
  count()

#aggregating by month and year
ACLED_month_total <- ACLED2 %>%
    group_by(month = lubridate::floor_date(event_date, 'month'),
             country) %>%
    summarize(fatalities_m = sum(fatalities),
              count_events_m = n()) %>%
  mutate(type = "All types of violent conflict")

ACLED_year_total <- ACLED_month_total %>%
    group_by(year = lubridate::floor_date(month, 'year'),
             country) %>%
    summarize(fatalities_y = sum(fatalities_m),
              count_events_y = sum(count_events_m))  %>%
  mutate(type = "All types of violent conflict")

#aggregating by type of conflict as well, adding to set
ACLED_month_types <- ACLED2 %>%
    group_by(month = lubridate::floor_date(event_date, 'month'),
             country, event_type) %>%
    summarize(fatalities_m = sum(fatalities),
              count_events_m = n(),
              type = event_type[1]) %>%
  dplyr::select(-event_type)

ACLED_month <- full_join(ACLED_month_total, ACLED_month_types)

ACLED_year_types <- ACLED2 %>%
    group_by(year = lubridate::floor_date(event_date, 'year'),
             country, event_type) %>%
    summarize(fatalities_y = sum(fatalities),
              count_events_y = n(),
              type = event_type[1]) %>%
  dplyr::select(-event_type)

ACLED_year <- full_join(ACLED_year_total, ACLED_year_types)

#prep to merge year-aggregated set with bigset 
#transform dates to readable/mergeable form
ACLED_month <- ACLED_month %>%
  mutate(month = format(month, "%b %Y"))

ACLED_year <- ACLED_year %>%
  mutate(year = format(year, "%Y"))

#pivot to long format and rename vars
ACLED_year <- ACLED_year %>% 
  pivot_longer(cols = 3:4, names_to = "Indicator.Name", values_to = "value") %>%
  mutate(Country.Name = country,
         Indicator.Name = paste0(Indicator.Name, ", ", type)) %>%
  dplyr::select(-type, -country)

ACLED_month <- ACLED_month %>% 
  pivot_longer(cols = 3:4, names_to = "Indicator.Name", values_to = "value") %>%
  mutate(Country.Name = country,
         Indicator.Name = paste0(Indicator.Name, ", ", type)) %>%
  dplyr::select(-type, -country)
```

##World Bank economic indicator data
World Bank data can be downloaded from their website 
(https://databank.worldbank.org/source/world-development-indicators).
Datasets included in the "All Research Documents (Feb-Sept 2024)" folder.
Many variables never used in resulting model.

Pivot other sets into usable format.
```{r pivot-econ-sets}
WB_businesses <- read.csv("WB_businesses.csv")
WB_businesses <- pivot_longer(data = WB_businesses, cols = 5:67, names_to = "year")
WB_businesses$year <- gsub("^.{0,1}", "", WB_businesses$year)

WB_economic_indicators <- read_excel("WB_economic_indicators.xlsx", .name_repair = "universal") 
WB_economic_indicators <- pivot_longer(data = WB_economic_indicators, cols = 5:67, names_to = "year")
WB_economic_indicators$year <- gsub("^.{0,3}", "", WB_economic_indicators$year)
WB_economic_indicators <- WB_economic_indicators %>%
  mutate(value = as.numeric(value))

WB_airports <- read.csv("airport_volume_airport_locations_WB.csv") %>%
  mutate(year = 2023)
```

Merge into a comprehensive country/year dataset.
```{r merge-econ-sets}
WB_economic_indicators <- WB_economic_indicators %>%
  mutate(Indicator.Name = Series.Name, Indicator.Code = Series.Code) %>%
  dplyr::select(-Series.Name, -Series.Code) %>%
  relocate(year, .after = last_col()) %>%
  relocate(value, .after = last_col())

bigset <- full_join(WB_economic_indicators, WB_businesses)

#checking to make sure it added the variable
bigset %>%
  filter(Indicator.Name == "New businesses registered (number)")
#we're good

WB_airports2 <- WB_airports %>%
  group_by(Country.Name) %>%
  summarize(AirportsCount = n(),
            AirportsVolume = sum(TotalSeats),
            year = mean(year)) 

#testing to make sure the variables work and are sortable
WB_airports2 %>%
  arrange(AirportsVolume) 
#great

WB_airports3 <- pivot_longer(data = WB_airports2, cols = 2:3, names_to = "Indicator.Name") 
bigset <- bigset %>%
  mutate(year = as.numeric(year))
bigset <- full_join(bigset, WB_airports3)

#checking to make sure it added the variable
bigset %>%
  filter(Indicator.Name == "AirportsVolume")
#we're good
```

Aggregate and merge ACLED indicators
```{r ACLED-tidy-2, eval=FALSE, include=FALSE}
#merge yearly set with bigset
bigset <- bigset %>% 
  mutate(year = as.character(year)) %>%
  full_join(ACLED_year)

#check merge
bigset %>%
  filter(Indicator.Name == "count_events_y, Protests")
#good
```

Isolate spellings that don't match
```{r spellings}
bigset %>%
  group_by(Country.Name) %>%
  summarize(Count = n()) %>%
  filter(Count < 100) %>%
  print(n = 50)

#search df
bigset %>%
  filter(grepl('tristan', Country.Name))

bigset <- bigset %>%
  mutate(Country.Name = case_when(
    Country.Name == "Democratic Republic of the Congo" ~ "Congo, Dem. Rep.",
    Country.Name == "Congo" ~ "Congo, Dem. Rep.",
    Country.Name == "Bahamas" ~ "Bahamas, The",
    Country.Name == "Cape Verde" ~ "Cabo Verde",
    Country.Name == "Czech Republic" ~ "Czechia",
    Country.Name == "East Timor" ~ "Timor-Leste",
    Country.Name == "Egypt" ~ "Egypt, Arab Rep.",
    Country.Name == "Gambia" ~ "Gambia, The", 
    Country.Name == "Guinea Bissau" ~ "Guinea-Bissau",
    Country.Name == "Iran" ~ "Iran, Islamic Rep.",
    Country.Name == "Ivory Coast (Cote d'Ivoire)" ~ "Cote d'Ivoire",
    Country.Name == "Kyrgyzstan" ~ "Kyrgyz Republic", 
    Country.Name == "Laos" ~ "Lao PDR",
    Country.Name == "Macedonia" ~ "North Macedonia",
    Country.Name == "Micronesia" ~ "Micronesia, Fed. Sts.",
    Country.Name == "North Korea" ~ "Korea, Dem. People's Rep.", 
    Country.Name == "Saint Kitts and Nevis" ~ "St. Kitts and Nevis",
    Country.Name == "Saint Lucia" ~ "St. Lucia",
    Country.Name == "Saint Vincent and Grenadines" ~ "St. Vincent and the Grenadines",
    Country.Name == "Saint Vincent and the Grenadines" ~ "St. Vincent and the Grenadines",
    Country.Name == "Slovakia" ~ "Slovak Republic",
    Country.Name == "South Korea" ~ "Korea, Rep.",
    Country.Name == "Swaziland" ~ "Eswatini",
    Country.Name == "Syria" ~ "Syrian Arab Republic",
    Country.Name == "Yemen" ~ "Yemen, Rep.",
    Country.Name == "Vietnam" ~ "Viet Nam",
    Country.Name == "Venezuela" ~ "Venezuela, RB",
    Country.Name == "Turkey" ~ "Turkiye",
    Country.Name == "Hong Kong (SAR)" ~ "Hong Kong SAR, China",
    Country.Name == "Macau (SAR)" ~ "Macao SAR, China",
    Country.Name == "Brunei" ~ "Brunei Darussalam",
    Country.Name == "West Bank and Gaza" ~ "Palestine",
    Country.Name == "Russia" ~ "Russian Federation",
    Country.Name == "Saint Martin" ~ "St. Martin (French part)",
    Country.Name == "Saint-Martin" ~ "St. Martin (French part)",
    Country.Name == "Sint Maarten" ~ "Sint Maarten (Dutch part)",
    Country.Name == "Saint-Barthelemy" ~ "Saint Barthelemy",
    TRUE ~ Country.Name)
  ) %>%
  filter(!(Country.Name %in% c("European Union", "Latin America & Caribbean", "Latin America & Caribbean (excluding high income)", "South Asia", "Sub-Saharan Africa (excluding high income)", "Grenada and South Grenadines", "Saint Helena, Ascension and Tristan da Cunha")))
# "grenada and south grenadines" overlap between country observations -- drop to be safe
# WB does not recognize Taiwan unfortunately

bigset %>%
  group_by(Country.Name) %>%
  summarize(Count = n()) %>%
  filter(Count < 150) %>%
  print(n = 50)
#Remainder are very small and isolated territories of other countries or unrecognized by WB as countries -- better to keep as their own entries
#Keep consistent labels for ease of adding other data if needed
```

Save our tidied datasets for further use
```{r writecsvs}
#write.csv(bigset, "data/master_dataset.csv")
#write.csv(ACLED_month, "data/ACLED_month.csv")

#Because the original ACLED daily data is not included in the replication files, 
#we will import the resulting master_dataset.csv later (which does include 
#ACLED, as generated with the code above).
```

##Bureau of Transport Statistics Flight data
The .asc files required for the following code can be downloaded from the Bureau of Transportation Statistics website. (https://www.bts.gov/browse-statistical-products-and-data/bts-
publications/data-bank-28im-t-100-and-t-100f-internationa-0)
ChatGPT was used to produce some of the framework for the code below, but modifications are the author's own work.

```{r merge-flights, eval=FALSE, include=FALSE}
# Set the working directory to where the data files are located
setwd("/Users/michelle/Documents/ukr2024/All Research Documents (Feb-Sept 2024)/backups/mar 5 backup/UKR-airports/data")

# List all .asc files in the directory
file_list <- list.files(pattern = "\\.asc$")

# Initialize an empty list to store data frames
data_list <- list()

# Function to handle missing values and remove the first row (header)
clean_data <- function(data) {
  # Remove first row (header) and convert it to column names
  col_names <- data[1, ]
  data <- data[-1, ]
  colnames(data) <- col_names
  
  # Replace "NA" strings with actual NA values
  data[data == "NA"] <- NA
  return(data)
}

# Loop through each file, read it, clean the data, and append it to the data list
for (file in file_list) {
  data <- read.csv(file, header = FALSE, sep = "|", stringsAsFactors = FALSE)
  data <- clean_data(data)
  
  # Only add the dataframe to data_list if it has the expected number of columns (20)
  if (ncol(data) == 20) {
    data_list[[file]] <- data
  } else {
    cat("Skipping file", file, "due to irregular dimensions.\n")
  }
}

# Combine all data frames into one if there are any
if (length(data_list) > 0) {
  # Combine all data frames into one
  full_data <- do.call(rbind, data_list)
  
  # Convert numeric columns from character to numeric
  num_cols <- c("Year", "Month", "Origin_Airport_ID", "Destination_Airport_ID", "Flight_Number", "Scheduled_Departures", "Scheduled_Seats", "Flights_Cancelled", "Flights_Diverted", "Scheduled_Passengers", "Actual_Passengers", "Flights_Departed", "Payload", "Seats", "Freight")
  full_data[, num_cols] <- lapply(full_data[, num_cols], as.numeric)
  
  # Optionally, you can save the merged dataset to a CSV file
  # write.csv(full_data, "merged_data.csv", row.names = FALSE)
  
  # Check the structure of the merged dataset
  str(full_data)
} else {
  cat("No valid data frames found. Check your data files for issues.")
}

# Adjust num_cols based on the actual column names
num_cols <- c("year", "month", "origin_wac", "origin_city_market_id", "dest_wac", "dest_city_market_id", "distance", "passengers", "freight", "mail")

# Convert numeric columns from character to numeric
full_data[, num_cols] <- lapply(full_data[, num_cols], as.numeric)

# Check the structure of the merged dataset
str(full_data)

# Adjust num_cols based on the actual column names, excluding the "NA" column
num_cols <- c("year", "month", "origin_wac", "origin_city_market_id", "dest_wac", "dest_city_market_id", "distance", "passengers", "freight", "mail")

# Remove "NA" from the column names
full_data <- full_data[, !colnames(full_data) %in% "NA"]

# Convert numeric columns from character to numeric
full_data[, num_cols] <- lapply(full_data[, num_cols], as.numeric)

# Check the structure of the merged dataset
str(full_data)

```

Extract country variables from city columns
```{r country-variables, eval=FALSE, include=FALSE}
# Function to extract country information
extract_country <- function(city_name) {
  # Split the city name by comma
  parts <- strsplit(city_name, ",")[[1]]
  
  # Extract the last part as the country
  country <- trimws(parts[length(parts)])
  
  # Convert state codes to "USA"
  if (country %in% state_codes) {
    country <- "USA"
  }
  
  return(country)
}

# Define a vector of 2-letter state codes
state_codes <- c("AL", "AK", "AZ", "AR", "CA", "CO", "CT", "DE", "FL", "GA", 
                 "HI", "ID", "IL", "IN", "IA", "KS", "KY", "LA", "ME", "MD", 
                 "MA", "MI", "MN", "MS", "MO", "MT", "NE", "NV", "NH", "NJ", 
                 "NM", "NY", "NC", "ND", "OH", "OK", "OR", "PA", "RI", "SC", 
                 "SD", "TN", "TX", "UT", "VT", "VA", "WA", "WV", "WI", "WY", 
                 "DC", "TT", "PR", "VI")

#Trust territories were administered by the US until this code stopped being used

# Create origin country column
full_data$origin_country <- sapply(full_data$origin_city_name, extract_country)

# Create destination country column
full_data$destination_country <- sapply(full_data$dest_city_name, extract_country)

# Display the first few rows of the updated dataset
head(full_data)

```

Aggregate by country and month
```{r aggregate-flights, eval=FALSE, include=FALSE}
x <- full_data %>%
  group_by(year, month, origin_country, destination_country) %>%
  summarize(total_passengers = sum(passengers),
            total_freight = sum(freight),
            total_mail = sum(mail),
            total_flights = n())

#testing for irregularities
x %>% 
  group_by(origin_country, destination_country, year, month) %>%
  count() %>%
  filter(n > 1)
#Great, no double counting

#making sure trust territories carried over properly
x %>% 
  group_by(origin_country, destination_country, year, month) %>%
  count() %>%
  filter(origin_country == "Palau" | destination_country == "Palau") %>%
  arrange(year)
#yes, these start being recorded in 1994, when it entered in free association with the US

#export
write.csv(x, "/Users/michelle/Documents/UKR-airports/data/flights_master.csv")
#x <- read.csv("/Users/michelle/Documents/UKR-airports/data/flights_master.csv")
```

Reshape flights dataset
```{r reshape-flights, eval=FALSE, include=FALSE}
y <- x %>% 
  mutate(country = case_when(origin_country != "USA" ~ origin_country,
                             destination_country != "USA" ~ destination_country),
         in_out = case_when(origin_country != "USA" ~ "out",
                             destination_country != "USA" ~ "in")) %>%
  mutate(total_freight_in = case_when(in_out == "out" ~ 0,
                                       in_out == "in" ~ total_freight),
         total_freight_out = case_when(in_out == "in" ~ 0,
                                       in_out == "out" ~ total_freight),
         total_mail_in = case_when(in_out == "out" ~ 0,
                                       in_out == "in" ~ total_mail),
         total_mail_out = case_when(in_out == "in" ~ 0,
                                       in_out == "out" ~ total_mail),
         total_passengers_in = case_when(in_out == "out" ~ 0,
                                       in_out == "in" ~ total_passengers),
         total_passengers_out = case_when(in_out == "in" ~ 0,
                                       in_out == "out" ~ total_passengers),
         total_flights_in = case_when(in_out == "out" ~ 0,
                                       in_out == "in" ~ total_flights),
         total_flights_out = case_when(in_out == "in" ~ 0,
                                       in_out == "out" ~ total_flights)) %>%
  group_by(country, year, month) %>%
  summarize(total_freight_in = sum(total_freight_in),
            total_freight_out = sum(total_freight_out),
            total_mail_in = sum(total_mail_in),
            total_mail_out = sum(total_mail_out),
            total_passengers_in = sum(total_passengers_in),
            total_passengers_out = sum(total_passengers_out),
            total_flights_in = sum(total_flights_in),
            total_flights_out = sum(total_flights_out))
#"in" describes into the country of interest, not into the US
```

Complete all rows in the dataset not included (nulls)
```{r complete-flights, eval=FALSE, include=FALSE}
library(tidyr)

# Convert factor columns to character or numeric
y$country <- as.character(y$country)
y$year <- as.numeric(y$year)
y$month <- as.numeric(y$month)

# Create a data frame with all combinations of country, year, and month
all_combinations <- expand.grid(
  country = unique(y$country),
  year = unique(y$year),
  month = unique(y$month)
)

# Merge or join all_combinations with your original data
complete_data <- merge(all_combinations, y, by = c("country", "year", "month"), all.x = TRUE)

# Fill missing values with 0
complete_data[is.na(complete_data)] <- 0

#Check to make sure it loaded properly
complete_data %>%
  filter(total_freight_in != 0 &
         total_freight_out != 0 &
         total_mail_in != 0 &
         total_mail_out != 0 &
         total_passengers_in != 0 &
         total_passengers_out != 0 &
         total_flights_in != 0 &
         total_flights_out != 0) %>%
  group_by(country) %>%
  count() %>%
  arrange(-n)

y %>%
  filter(total_freight_in != 0 &
         total_freight_out != 0 &
         total_mail_in != 0 &
         total_mail_out != 0 &
         total_passengers_in != 0 &
         total_passengers_out != 0 &
         total_flights_in != 0 &
         total_flights_out != 0) %>%
  group_by(country) %>%
  count() %>%
  arrange(-n)

#They're the same. Success :)

y <- complete_data
```

##Generate percentage change variables (US flight data)
Code to generate the "change in flights" variables is below.
Results will be in percentage change terms (Since they were multiplied by 100).
If the value from the previous year was 0, the change was calculated with a denominator set to .5 (preventing an "Inf" result and producing a result as if the baseline were just .75 of a flight, still showing an increase if 1 singular flight is recorded).

```{r year-flights}
setwd("/Users/michelle/Documents/ukr2024/All Research Documents (Feb-Sept 2024)/backups/mar 5 backup/UKR-airports/data")
y <- read_csv("master_dataset.csv")

z <- y %>%
    group_by(Country.Name, year, Indicator.Name) %>%
    summarize(value = sum(value)) 

subset <- z %>%
  filter(startsWith(Indicator.Name, "total_"))

subset <- subset %>%
  pivot_wider(names_from = Indicator.Name, values_from = value)


changes <- subset %>%
  arrange(Country.Name, year) %>%
  ungroup() %>%
  group_by(Country.Name) %>%
  mutate(
    flights_in_change_pct = ifelse(
      is.na(lag(total_flights_in)), NA,
      ifelse(
        lag(total_flights_in) != 0,
        ((total_flights_in - lag(total_flights_in)) / lag(total_flights_in)) * 100,
        ((total_flights_in - lag(total_flights_in)) / 0.75) * 100
      )
    ),
    
    passengers_in_change_pct = ifelse(
      is.na(lag(total_passengers_in)), NA,
      ifelse(
        lag(total_passengers_in) > 100, #there are some non-meaningful (non-commercial) low levels we need to ignore
        ((total_passengers_in - lag(total_passengers_in)) / lag(total_passengers_in)) * 100,
        ((total_passengers_in - lag(total_passengers_in)) / 100) * 100
      )                                          #using 100 passengers as a baseline 
    ),
    
    mail_in_change_pct = ifelse(
      is.na(lag(total_mail_in)), NA,
      ifelse(
        lag(total_mail_in) != 0,
        ((total_mail_in - lag(total_mail_in)) / lag(total_mail_in)) * 100,
        ((total_mail_in - lag(total_mail_in)) / 0.75) * 100
      )
    ),
    
    freight_in_change_pct = ifelse(
      is.na(lag(total_freight_in)), NA,
      ifelse(
        lag(total_freight_in) != 0,
        ((total_freight_in - lag(total_freight_in)) / lag(total_freight_in)) * 100,
        ((total_freight_in - lag(total_freight_in)) / 0.75) * 100
      )
    ),
    
    flights_out_change_pct = ifelse(
      is.na(lag(total_flights_out)), NA,
      ifelse(
        lag(total_flights_out) != 0,
        ((total_flights_out - lag(total_flights_out)) / lag(total_flights_out)) * 100,
        ((total_flights_out - lag(total_flights_out)) / 0.75) * 100
      )
    ),
    
    passengers_out_change_pct = ifelse(
      is.na(lag(total_passengers_out)), NA,
      ifelse(
        lag(total_passengers_out) > 100,
        ((total_passengers_out - lag(total_passengers_out)) / lag(total_passengers_out)) * 100,
        ((total_passengers_out - lag(total_passengers_out)) / 100) * 100
      )
    ),
    
    mail_out_change_pct = ifelse(
      is.na(lag(total_mail_out)), NA,
      ifelse(
        lag(total_mail_out) != 0,
        ((total_mail_out - lag(total_mail_out)) / lag(total_mail_out)) * 100,
        ((total_mail_out - lag(total_mail_out)) / 0.75) * 100
      )
    ),
    
    freight_out_change_pct = ifelse(
      is.na(lag(total_freight_out)), NA,
      ifelse(
        lag(total_freight_out) != 0,
        ((total_freight_out - lag(total_freight_out)) / lag(total_freight_out)) * 100,
        ((total_freight_out - lag(total_freight_out)) / 0.75) * 100
      )
    )
  )
```

Let's deal with the outliers produced by going from 0 to a high flight number by dropping everything on and before that year. (If it wasn't an extreme result, we keep it, because it still represents an increase from 0. Recall that we set the division by a baseline of 100 to minimize extreme results)
```{r clean_pct}
ggplot(data=changes, mapping = aes(x=year,y=passengers_in_change_pct)) +
  geom_point()

# Identify the first year with passengers_in_change_pct > 2500 for each country
high_increase_years <- changes %>%
  filter(passengers_in_change_pct > 2500) %>%
  group_by(Country.Name) %>%
  summarize(first_high_year = min(year)) %>%
  ungroup() %>%
  arrange(first_high_year)

# Remove all observations for those countries on or before the year of the first high increase
changes <- changes %>%
  left_join(high_increase_years, by = "Country.Name") %>%
  filter(is.na(first_high_year) | year > first_high_year) %>%
  select(-first_high_year)

#Reiterate to catch leftovers

# Identify the first year with passengers_in_change_pct > 2500 for each country
high_increase_years <- changes %>%
  filter(passengers_in_change_pct > 2500) %>%
  group_by(Country.Name) %>%
  summarize(first_high_year = min(year)) %>%
  ungroup() %>%
  arrange(first_high_year)

# Remove all observations for those countries on or before the year of the first high increase
changes <- changes %>%
  left_join(high_increase_years, by = "Country.Name") %>%
  filter(is.na(first_high_year) | year > first_high_year) %>%
  select(-first_high_year)

# Plot to verify the removal
ggplot(data = changes, mapping = aes(x = year, y = passengers_in_change_pct)) +
  geom_point()

changes <- changes %>%
  pivot_longer(cols = 3:ncol(changes),
               names_to = "Indicator.Name", values_to = "value")
```

Merge with master dataset
```{r merge-flights-master}
master_dataset <- y %>%
  filter(!str_detect(Indicator.Name, "change_pct")) %>%
  full_join(changes, by = c("Country.Name", "year", "Indicator.Name", "value"))

#export new master set
write.csv(master_dataset, "master_dataset2.csv")
```



##Standardizing country names, timelines, removing duplicates, handling NAs

```{r packages-2, message=FALSE, warning=FALSE}
library(tidyverse)
library(dplyr)
library(readr)
library(readxl)
library(naniar)
#install.packages("readr", repos = "http://cran.us.r-project.org")
#install.packages("microsynth", repos = "http://cran.us.r-project.org")
#install.packages("LowRankQP", repos = "http://cran.us.r-project.org")
library("readr")
library("microsynth")
library("LowRankQP")
```

Handling naming difference for Kyrgyzstan
```{r ukraine-fill-in-2023}
#I noticed later that Kyrgyzstan needs standardized names.
data_master <- master_dataset %>%
  mutate(Country.Name = case_when(Country.Name == "Kyrgyz Republic" ~ "Kyrgyzstan",
                                   Country.Name == "Kyrgyzstan" ~ "Kyrgyzstan",
                                   (Country.Name != "Kyrgyzstan" & Country.Name != "Kyrgyz Republic") ~ Country.Name))
```

Remove duplicate observations, which are caused by error in data merging (will fix if time)
```{r duplicates}
# Identify duplicates
duplicate_rows <- data_master %>%
  filter(Indicator.Name %in% c("fatalities_y, Violence against civilians", "fatalities_y, Strategic developments", "fatalities_y, Protests", "fatalities_y, Explosions/Remote violence", "fatalities_y, Battles", "count_events_y, Violence against civilians", "count_events_y, Strategic developments", "count_events_y, Protests", "count_events_y, Explosions/Remote violence", "count_events_y, Battles", "count_events_y, All types of violent conflict", "AirportsVolume", "AirportsCount", "GDP growth (annual %)", "Tax revenue (% of GDP)", "Inflation, GDP deflator (annual %)", "passengers_spike_true", "flights_spike_true", "total_passengers_in", "total_passengers_out", "total_flights_in", "total_flights_out", "total_freight_in", "total_freight_out", "Foreign direct investment, net inflows (% of GDP)"),
         year >= 2000) %>%
  group_by(Country.Name, year, Indicator.Name) %>%
  summarise(n = n()) %>%
  filter(n > 1)

# View duplicate rows (if any)
print(duplicate_rows)

#Let's just drop the duplicates, plus the errors with Tristan da Cunha and other comma'd territories that got split incorrectly. I will fix these more directly if I have time, but omitting them from the regression just reduces the sample size, which should have a minimal effect on inference.
data_master <- data_master %>%
  filter(!(Country.Name == "Congo, Dem. Rep." & (Indicator.Name == "AirportsCount" | Indicator.Name == "AirportsVolume") & year == 2023))
```

I ended up deciding to cut the inference to pre-COVID (2010-2019), cutting out data measurement issues in the COVID period and as a result of the Russo-Ukraine war. Therefore, I cut much of my processing regarding a lack of 2023 data entries, especially if the code chunk was purely about this issue.

The data is called "scm_data" below since it was originally created for the SCM model, but it is used in later unrelated models too.
```{r specifications}
scm_data <- data_master %>%
  filter(Indicator.Name %in% c("fatalities_y, Violence against civilians", "fatalities_y, Strategic developments", "fatalities_y, Protests", "fatalities_y, Explosions/Remote violence", "fatalities_y, Battles", "count_events_y, Violence against civilians", "count_events_y, Strategic developments", "count_events_y, Protests", "count_events_y, Explosions/Remote violence", "count_events_y, Battles", "count_events_y, All types of violent conflict", "AirportsVolume", "AirportsCount", "GDP growth (annual %)", "Inflation, GDP deflator (annual %)", "passengers_spike_true", "flights_spike_true", "total_passengers_in", "total_passengers_out", "total_flights_in", "total_flights_out", "total_freight_in", "total_freight_out", "Foreign direct investment, net inflows (% of GDP)", "GDP (current US$)", "flights_in_change_pct", "passengers_in_change_pct"),
         year >= 2000, year <= 2019) %>%
  pivot_wider(names_from = Indicator.Name, values_from = value) %>%
  group_by(Country.Name, year) %>%
  summarise_all(~ if (any(!is.na(.))) .[!is.na(.)][1] else NA)
#Note: you can add variables in the filter above and export the resulting dataset in order to add more columns. for instance, add: , "GDP (current US$)", "flights_in_change_pct", "passengers_in_change_pct"
```

We have a problem with NA values. Let's fill in all ACLED and flight-count cases with NA with 0, since if they weren't included, there were no events, counts, fatalities, and so on. 
```{r na}
library(zoo)

#1: ACLED and flight data -> 0 

# Define the variables to impute NAs with 0
variables_to_impute <- c("fatalities_y, Violence against civilians", "fatalities_y, Strategic developments", 
                         "fatalities_y, Protests", "fatalities_y, Explosions/Remote violence", "fatalities_y, Battles", 
                         "count_events_y, Violence against civilians", "count_events_y, Strategic developments", 
                         "count_events_y, Protests", "count_events_y, Explosions/Remote violence", "count_events_y, Battles", 
                         "count_events_y, All types of violent conflict",
                         "total_passengers_in", "total_passengers_out", "total_flights_in", "total_flights_out", 
                         "total_freight_in", "total_freight_out")

# Impute NAs with 0 for the specified variables
scm_data_imputed <- scm_data %>%
  mutate_at(vars(all_of(variables_to_impute)), ~ifelse(is.na(.), 0, .))

# Filter the dataset to find NAs in the specified variables
scm_data_imputed %>%
  filter(if_any(all_of(variables_to_impute), is.na))
#Success!


#some rows still have NAs. It seems like they are small countries or incorrectly named countries. Let's just drop them for simplicity.
scm_data_imputed <- na.omit(scm_data_imputed)
```

To know the earliest year of data for each country, let's generate a dataframe.
```{r na-obs}
min_years_per_country <- scm_data_imputed %>%
  group_by(Country.Name) %>%
  summarize(min_year = min(year))
```

It will return an error if there are spaces in the columns. Let's fix that.
```{r col-fill}
colnames(scm_data_imputed) <- gsub(" ", "_", colnames(scm_data_imputed))
colnames(scm_data_imputed) <- gsub("%", "pct", colnames(scm_data_imputed))
colnames(scm_data_imputed) <- gsub("\\(|\\)", "", colnames(scm_data_imputed))
colnames(scm_data_imputed) <- gsub(",", "", colnames(scm_data_imputed))
```

```{r export-data}
colnames(scm_data_imputed) <- gsub("_", ".", colnames(scm_data_imputed))
write.csv(scm_data_imputed, "scm_data2.csv")
```


##Import more WB indicators: GDP variations
May/June 2024, added more variables to the analysis for multiple OLS.

```{r}
library(tidyverse)
library(dplyr)
library(readr)
library(readxl)
library(naniar)
#install.packages("readr", repos = "http://cran.us.r-project.org")
#install.packages("microsynth", repos = "http://cran.us.r-project.org")
#install.packages("LowRankQP", repos = "http://cran.us.r-project.org")
library("readr")
library("microsynth")
library("LowRankQP")
#install.packages("plm")
library(plm)
library(lmtest)
library(modelsummary)

setwd('/Users/michelle/Documents/ukr2024/All Research Documents (Feb-Sept 2024)')
data <- read_csv("backups/mar 5 backup/UKR-airports/data/scm_data2.csv")
```

Add in PPP GDP & per capita measures from WB, plus the correct deflator.
```{r ppp, message=FALSE, warning=FALSE}
#deleted header rows with metadata to allow for easy import
ppp_pc <- read_csv("data/gdp_ppp_per capita_constantUSD.csv")
ppp <- read_csv("data/gdp_ppp_constantUSD.csv")
gdp_deflator <- read_csv("data/gdp_deflator.csv")

#let's pivot and merge these together
ppp <- ppp %>%
  pivot_longer(cols = where(is.numeric), names_to = "year") %>%
  mutate(value = as.numeric(value)) %>%
  filter(!is.na(value)) %>%
  dplyr::select(1,3, year, value) %>%
  mutate(year = as.numeric(year))

ppp_pc <- ppp_pc %>%
  pivot_longer(cols = where(is.numeric), names_to = "year") %>%
  mutate(value = as.numeric(value)) %>%
  filter(!is.na(value)) %>%
  dplyr::select(1,3, year, value) %>%
  mutate(year = as.numeric(year))

gdp_deflator <- gdp_deflator %>%
  pivot_longer(cols = 5:28, names_to = "year") %>%
  mutate(value = as.numeric(value)) %>%
  filter(!is.na(value)) %>%
  mutate(year = as.numeric(year),
         `Indicator Name` = `Series Name`) %>%
  dplyr::select(3, year, value, 7) 

ppp <- ppp %>% 
  full_join(ppp_pc) %>%
  full_join(gdp_deflator) %>%
  group_by(`Country Name`, year, `Indicator Name`) %>%
  summarise_all(~ if (any(!is.na(.))) .[!is.na(.)][1] else NA)


colnames(ppp) <- c("Country.Name", "year", "Indicator.Name", "value")

ppp <- ppp %>%
  pivot_wider(names_from = Indicator.Name, values_from = value) 

#standardize names:
ppp <- ppp %>%
  mutate(Country.Name = case_when(
    Country.Name == "Democratic Republic of the Congo" ~ "Congo, Dem. Rep.",
    Country.Name == "Congo" ~ "Congo, Dem. Rep.",
    Country.Name == "Bahamas" ~ "Bahamas, The",
    Country.Name == "Cape Verde" ~ "Cabo Verde",
    Country.Name == "Czech Republic" ~ "Czechia",
    Country.Name == "East Timor" ~ "Timor-Leste",
    Country.Name == "Egypt" ~ "Egypt, Arab Rep.",
    Country.Name == "Gambia" ~ "Gambia, The", 
    Country.Name == "Guinea Bissau" ~ "Guinea-Bissau",
    Country.Name == "Iran" ~ "Iran, Islamic Rep.",
    Country.Name == "Ivory Coast (Cote d'Ivoire)" ~ "Cote d'Ivoire",
    Country.Name == "Kyrgyzstan" ~ "Kyrgyz Republic", 
    Country.Name == "Laos" ~ "Lao PDR",
    Country.Name == "Macedonia" ~ "North Macedonia",
    Country.Name == "Micronesia" ~ "Micronesia, Fed. Sts.",
    Country.Name == "North Korea" ~ "Korea, Dem. People's Rep.", 
    Country.Name == "Saint Kitts and Nevis" ~ "St. Kitts and Nevis",
    Country.Name == "Saint Lucia" ~ "St. Lucia",
    Country.Name == "Saint Vincent and Grenadines" ~ "St. Vincent and the Grenadines",
    Country.Name == "Saint Vincent and the Grenadines" ~ "St. Vincent and the Grenadines",
    Country.Name == "Slovakia" ~ "Slovak Republic",
    Country.Name == "South Korea" ~ "Korea, Rep.",
    Country.Name == "Swaziland" ~ "Eswatini",
    Country.Name == "Syria" ~ "Syrian Arab Republic",
    Country.Name == "Yemen" ~ "Yemen, Rep.",
    Country.Name == "Vietnam" ~ "Viet Nam",
    Country.Name == "Venezuela" ~ "Venezuela, RB",
    Country.Name == "Turkey" ~ "Turkiye",
    Country.Name == "Hong Kong (SAR)" ~ "Hong Kong SAR, China",
    Country.Name == "Macau (SAR)" ~ "Macao SAR, China",
    Country.Name == "Brunei" ~ "Brunei Darussalam",
    Country.Name == "West Bank and Gaza" ~ "Palestine",
    Country.Name == "Saint Martin" ~ "St. Martin (French part)",
    Country.Name == "Saint-Martin" ~ "St. Martin (French part)",
    Country.Name == "Sint Maarten" ~ "Sint Maarten (Dutch part)",
    Country.Name == "Saint-Barthelemy" ~ "Saint Barthelemy",
    Country.Name == "Russian Federation" ~ "Russia",
    Country.Name == "Iran, Islamic Rep." ~ "Iran",
    Country.Name == "Brunei Darussalam" ~ "Brunei",
    Country.Name == "Congo (Kinshasa)" ~ "Congo, Dem. Rep.",
    Country.Name == "Congo (Brazaville)" ~ "Congo, Rep.",
    Country.Name == "Democratic Republic of Congo" ~ "Congo, Dem. Rep.",
    Country.Name == "Republic of Congo" ~ "Congo, Rep.",
    Country.Name == "Czech Republic" ~ "Czechia",
    Country.Name == "Egypt, Arab Rep." ~ "Egypt",
    Country.Name == "Hong Kong SAR, China" ~ "Hong Kong",
    Country.Name == "Ivory Coast" ~ "Cote d'Ivoire",
    Country.Name == "Lao PDR" ~ "Laos", 
    Country.Name == "Macao SAR, China" ~ "Macau",
    Country.Name == "Macedonia" ~ "North Macedonia",
    Country.Name == "Slovak Republic" ~ "Slovakia",
    Country.Name == "South Korea" ~ "Korea, Rep.",
    Country.Name == "North Korea" ~ "Korea, Dem. People's Rep.",
    Country.Name == "Syrian Arab Republic" ~ "Syria",
    Country.Name == "Turkey" ~ "Turkiye",
    Country.Name == "Venezuela, RB" ~ "Venezuela",
    Country.Name == "Viet Nam" ~ "Vietnam",
    Country.Name == "Kyrgyz Republic" ~ "Kyrgyzstan",
    Country.Name == "Yemen, Rep." ~ "Yemen",
    TRUE ~ Country.Name)
  ) %>%
  filter(!(Country.Name %in% c("European Union", "Latin America & Caribbean", "Latin America & Caribbean (excluding high income)", "South Asia", "Sub-Saharan Africa (excluding high income)", "Grenada and South Grenadines", "Saint Helena, Ascension and Tristan da Cunha", "U.S.S.R.", "West Germany"))) 
  #no need to delete aggregated entities (ie. "West Africa") — they'll drop when we merge with the main dataframe!

data <- data %>%
  left_join(ppp, by = c("Country.Name", "year"))
```

Create some logged variables:
```{r vars, message=FALSE, warning=FALSE}
data <- data %>% 
  mutate(total_FDI_n = (Foreign.direct.investment.net.inflows.pct.of.GDP * `GDP.current.US$` / 100),
         total_FDI_r = (Foreign.direct.investment.net.inflows.pct.of.GDP * `GDP, PPP (constant 2017 international $)` / 100),
    log_FDI_n = log1p(total_FDI_n),
    log_FDI_r = log1p(total_FDI_r),
    ihs_FDI_n = asinh(total_FDI_n),
    ihs_FDI_r = asinh(total_FDI_r),
    log_GDP_n = log1p(`GDP.current.US$`),
    log_GDP_r = log1p(`GDP, PPP (constant 2017 international $)`),
    log_GDP_r_pc = log1p(`GDP per capita, PPP (constant 2017 international $)`),
    log_battle = log1p(fatalities.y.Battles))
```

We can switch between the two nominal GDP measures by trading total_GDP_n_ID for `GDP.current.US$` (and vice versa).

Guide to new variables:
total_FDI_n = nominal total FDI (using GDP in constant 2017 international$, which was calculated using GDP deflator from PPP measures)
total_FDI_r = real total FDI (from PPP GDP numbers in current $US)
log_FDI_n = nominal total FDI, with log+1 transformation
log_FDI_r = real total FDI, with log+1 transformation
ihs_FDI_n = nominal total FDI, with IHS transformation
ihs_FDI_r = real total FDI, with IHS transformation
log_GDP_n = nominal GDP, logged+1
log_GDP_r = real GDP, logged+1
log_GDP_r_pc = real GDP per capita, logged+1
log_battle = battle fatalities, logged+1

##Export finished dataframe

```{r save}
setwd("/Users/michelle/Documents/ukr2024/Replication files")
write.csv(data, "full_data.csv")
```


